% Set up the document
\documentclass{article}

% Page size
\usepackage[
    letterpaper,]{geometry}

% Lines between paragraphs
\setlength{\parskip}{\baselineskip}
\setlength{\parindent}{0pt}

% Math
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{commath}

% Fancy typesetting
\newcommand{\A}{\mathcal{A}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\ex}{\mathbf{e}_1}
\newcommand{\ey}{\mathbf{e_2}}

% Number sets
\newcommand{\C}{\mathcal{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}

% Links
\usepackage{hyperref}

% Page numbers at top right
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\renewcommand\headrulewidth{0pt}

\begin{document}

\textbf{MATH 320 Homework 8} \\
\textbf{Matt Wiens \#301294492} \\
\textbf{2020-04-14}

1. Let $f: \R^2 \to \R^2$ and $g: \R^2 \to \R^2$ be defined by
%
\begin{align*}
    f(x, y) &= (x \sin y, \ \cos(x+y)), \\
    g(x, y) &= (x^2 y, \ \log (1+(x+y)^2))
    .
\end{align*}
%
Use the chain rule (instead of finding the explicit formula of $f \circ
g$) to find $D(f \circ g)$ at $(1, 0)$.

\textit{Solution.}
First, we will compute $D f$ and $D g$ (computing these is a calculus
problem so I will the partial derivatives by inspection since they
are simple enough):
%
\begin{align*}
    D f
    &=
        \begin{pmatrix}
            \partial_x f_1 & \partial_y f_1 \\
            \partial_x f_2 & \partial_y f_2
        \end{pmatrix}
    =
        \begin{pmatrix}
            \sin y & x \cos y \\
            - \sin(x + y) & - \sin(x + y)
        \end{pmatrix}
        ,
    \\
    D g
    &=
        \begin{pmatrix}
            \partial_x g_1 & \partial_y g_1 \\
            \partial_x g_2 & \partial_y g_2
        \end{pmatrix}
    =
        \begin{pmatrix}
            2 x y & x^2 \\[5pt]
            2 \dfrac{x + y}{1 + (x + y)^2} & 2 \dfrac{x + y}{1 + (x + y)^2}
        \end{pmatrix}
        .
\end{align*}
%
Next, we will compute $\eval[0]{D g}_{(1, 0)}$ and $\eval[0]{D f}_{g(1,
0)}$. Using our above expression for $D g$, we have
%
\begin{equation*}
    \eval[0]{D g}_{(1, 0)}
    =
    \eval{
        \begin{pmatrix}
            2 x y & x^2 \\[5pt]
            2 \dfrac{x + y}{1 + (x + y)^2} & 2 \dfrac{x + y}{1 + (x + y)^2}
        \end{pmatrix}
    }_{(1, 0)}
    =
        \begin{pmatrix}
            0 & 1 \\
            1 & 1
        \end{pmatrix}
    .
\end{equation*}
%
Noting that
%
\begin{equation*}
    g(1, 0) = (0, \log 2)
    ,
\end{equation*}
%
we have that
%
\begin{equation*}
    \eval[0]{D f}_{g(1, 0)}
    =
    \eval[0]{D f}_{(0, \log 2)}
    =
    \eval{
        \begin{pmatrix}
            \sin y & x \cos y \\
            - \sin(x + y) & - \sin(x + y)
        \end{pmatrix}
    }_{(0, \log 2)}
    =
        \begin{pmatrix}
            \sin(\log 2) & 0 \\
            - \sin(\log 2) & - \sin(\log 2)
        \end{pmatrix}
    .
\end{equation*}
%
Therefore, using the chain rule we have that
%
\begin{align*}
    \eval[0]{D(f \circ g)}_{(1, 0)}
    &= \eval[0]{D f}_{g(1, 0)} \eval[0]{D g}_{(1, 0)}
    \\
    &=
        \begin{pmatrix}
            \sin(\log 2) & 0 \\
            - \sin(\log 2) & - \sin(\log 2)
        \end{pmatrix}
        \begin{pmatrix}
            0 & 1 \\
            1 & 1
        \end{pmatrix}
        \\
    & =
        \begin{pmatrix}
            0 & \sin(\log 2) \\
            - \sin(\log 2) & - 2 \sin(\log 2)
        \end{pmatrix}
        .
\end{align*}

\newpage

2. Let $f: \R^k \to \R^n$ and $g: \R^k \to \R^n$ be differentiable
mappings. Use the definition of the derivative to show that $\alpha f
+ \beta g: \R^k \to \R^n$ is differentiable for any $\alpha, \beta
\in \R$.

\textit{Solution.}
Let $x_0 \in \R^k$. We need to show that there exists a bounded linear
transformation $\A: \R^k \to \R^n$ and a function $R: \R^k \to \R^n$
such that the following hold:
%
\begin{align}
    (\alpha f + \beta g)(x_0 + h)
        &=
        (\alpha f + \beta g)(x_0)
        + \A h
        + R(h),
    \label{eq:2-1}
    \\
    \lim_{|h| \to 0} \frac{|R(h)|}{|h|} &= 0.
    \label{eq:2-2}
\end{align}
%
Since $f$ and $g$ are both differentiable, there exist linear
transformations $\A_f, \A_g: \R^k \to \R^n$ and functions $R_f, R_g:
\R^k \to \R^n$ such that
%
\begin{align}
    f(x_0 + h) &= f(x_0) + \A_f h + R_f(h), \label{eq:2-3} \\
    g(x_0 + h) &= g(x_0) + \A_g h + R_g(h), \label{eq:2-4}
\end{align}
%
and also
%
\begin{equation*}
    \lim_{|h| \to 0} \frac{|R_f(h)|}{|h|} = 0, \quad
    \lim_{|h| \to 0} \frac{|R_g(h)|}{|h|} = 0.
\end{equation*}
%
First, note that for any $x \in \R^k$ we can write
%
\begin{equation*}
    (\alpha f + \beta g)(x) = \alpha f(x) + \beta g(x)
    .
\end{equation*}
%
Then, by multiplying~\eqref{eq:2-3} and~\eqref{eq:2-4} through by
$\alpha$ and $\beta$, respectively, and taking their sum, we obtain
%
\begin{align*}
    (\alpha f + \beta g)(x_0 + h)
        &= \alpha f(x_0 + h) + \beta g(x_0 + h) \\
        &= \alpha \del{f(x_0) + \A_f h + R_f(h)}
            + \beta \del{g(x_0) + \A_g h + R_g(h)} \\
        &= (\alpha f + \beta g)(x_0)
            + (\alpha \A_f + \beta \A_g) h
            + (\alpha R_f + \beta R_g)(h).
\end{align*}
%
Hence
%
\begin{equation}
    (\alpha f + \beta g)(x_0 + h)
        = (\alpha f + \beta g)(x_0)
            + (\alpha \A_f + \beta \A_g) h
            + (\alpha R_f + \beta R_g)(h).
        \label{eq:2-5}
\end{equation}
%
Note that because $\A_f$ and $\A_g$ are linear transformations with the
same domain and codomain, any linear combination of these
transformations is also a linear transformation; hence $\alpha A_f +
\beta A_g$ is a linear transformation.

We also have that
%
\begin{align*}
    \lim_{|h| \to 0} \frac{|(\alpha R_f + \beta R_g)(h)|}{|h|}
        &= \lim_{|h| \to 0} \frac{|\alpha R_f(h) + \beta R_g(h)|}{|h|} \\
        &\leq \lim_{|h| \to 0} \del{
            \frac{|\alpha R_f(h)|}{|h|} + \frac{|\beta R_g(h)|}{|h|}
        } \\
        &=
            |\alpha| \lim_{|h| \to 0} \frac{|R_f(h)|}{|h|}
            + |\beta| \lim_{|h| \to 0} \frac{|R_g(h)|}{|h|} \\
        &= |\alpha| 0 + |\beta| 0 \\
        &= 0.
\end{align*}
%
Therefore,
%
\begin{equation}
    \lim_{|h| \to 0} \frac{|(\alpha R_f + \beta R_g)(h)|}{|h|} = 0.
    \label{eq:2-6}
\end{equation}
%
Hence if we take $\A = \alpha \A_f + \beta \A_g$ and $R = \alpha R_f +
\beta R_g$, in~\eqref{eq:2-1} and~\eqref{eq:2-2}, then according
to~\eqref{eq:2-5} and~\eqref{eq:2-6}, $(\alpha f + \beta g)$ is
differentiable at $x_0$. Since $x_0$ (and further $\alpha$ and $\beta$)
was arbitrary, it follows that $(\alpha f + \beta g)$ is differentiable
for any $\alpha, \beta \in \R$.

\newpage

3. Consider the function $f: \R^2 \to \R$ given by
%
\begin{equation*}
    f(x, y)
    = \begin{cases}
        \dfrac{x y}{x^2 + y^2}, & (x, y) \neq (0, 0), \\
        0, & (x, y) = (0, 0).
   \end{cases}
\end{equation*}
%
Show that $\partial x f$ and $\partial y f$ both exist at $(0, 0)$ but
$f$ is not differentiable at $(0, 0)$, hence $D f$ does not exist at
$(0, 0)$.

\textit{Solution.}
First, note that $f$ is not continuous at $(0, 0)$ and hence is
not differentiable there. This is because
%
\begin{equation*}
    \lim_{k \to 0} f(k, k)
        = \lim_{k \to 0} \frac{k^2}{2 k^2}
        = \frac{1}{2} \neq 0
        = f(0, 0)
    .
\end{equation*}
%
However, both partial derivatives $\partial_x f$ and $\partial_y f$
exist at $(0, 0)$. To see this, denote $\0 = (0, 0) \in \R^2$, and let
$\ex, \ey$ be the standard unit vectors in the $x$ and $y$ directions,
respectively. Note that by the definition of $f$ that for any $t \in \R$,
%
\begin{equation*}
    f(\0) = f(0, 0) = 0, \quad
    f(t \ex) = f(t, 0) = 0, \quad
    \text{and} \qquad f(t \ey) = f(0, t) = 0
    .
\end{equation*}
%
Hence we have that
%
\begin{align*}
    \dpd{f}{x}(\0)
        &= \lim_{t \to 0} \frac{f(\0 + t \ex) - f(\0)}{t} \\
        &= \lim_{t \to 0} \frac{f(t \ex) - f(\0)}{t} \\
        &= \lim_{t \to 0} \frac{0 - 0}{t} \\
        &= 0; \\
    \dpd{f}{y}(\0)
        &= \lim_{t \to 0} \frac{f(\0 + t \ey) - f(\0)}{t} \\
        &= \lim_{t \to 0} \frac{f(t \ey) - f(\0)}{t} \\
        &= \lim_{t \to 0} \frac{0 - 0}{t} \\
        &= 0
        .
\end{align*}

\newpage

4. Consider the two equations
%
\begin{align*}
    x^2 - y^2 - u^3 + v^2 + 4 = 0
    \quad \text{and} \quad
    2 x y + y^2 - 2 u^2 + 3 v^4 + 8 = 0
    .
\end{align*}
%
Show that near the point $(x, y, u, v) = (2, -1, 2, 1)$, we can solve
for $(u, v)$ in terms of $(x, y)$.

\textit{Solution.}

\end{document}
